{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5e7fa5-a26e-43cc-ba56-eeab754cf586",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "import tensorflow_io as tfio\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, Conv2D\n",
    "from tensorflow.keras.metrics import TruePositives, TrueNegatives, FalsePositives, FalseNegatives\n",
    "from sklearn.model_selection import train_test_split\n",
    "import librosa\n",
    "from pydub import AudioSegment\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c3a19e-03db-477a-93c8-7c121043ee6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_spoof = \"idrd/Training_Data/spoof/\"\n",
    "path_human = \"idrd/Training_Data/human/\"\n",
    "path_test = \"idrd/Testing_Data/\"\n",
    "\n",
    "spoof_list_path = [path_spoof + i for i in os.listdir(path_spoof)]\n",
    "human_list_path = [path_human + i for i in os.listdir(path_human)]\n",
    "test_list_path = [path_test + i for i in os.listdir(path_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5fa715-147a-4ca6-99b3-09d86cd062c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_slice_audio(path_load, path_write, seconds):\n",
    "    audio = AudioSegment.from_wav(path_load)\n",
    "    n = re.search(r'\\d+', path_load).group(0)\n",
    "    start = 0\n",
    "    end = seconds*1000 # ms\n",
    "    for i in range(len(audio)//(seconds*1000)):\n",
    "        slice_audio = audio[start:end]\n",
    "        start = end\n",
    "        end += seconds*1000\n",
    "        slice_audio.export(f'{path_write}{n}.{i+1}.wav', format=\"wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f5bdb1-068c-4ca1-8a30-c142d64eb957",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "[write_slice_audio(i, 'idrd/Slice_Training_Data/spoof/', 2) for i in tqdm(spoof_list_path)]\n",
    "[write_slice_audio(i, 'idrd/Slice_Training_Data/human/', 2) for i in tqdm(human_list_path)]\n",
    "[write_slice_audio(i, 'idrd/Slice_Testing_Data/', 2) for i in tqdm(test_list_path)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b895b9da-a295-4329-a6b7-caa4cabc9e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_spoof = \"idrd/Slice_Training_Data/spoof/\"\n",
    "path_human = \"idrd/Slice_Training_Data/human/\"\n",
    "path_test = \"idrd/Slice_Testing_Data/\"\n",
    "\n",
    "spoof_list_path = [path_spoof + i for i in os.listdir(path_spoof)]\n",
    "human_list_path = [path_human + i for i in os.listdir(path_human)]\n",
    "test_list_path = [path_test + i for i in os.listdir(path_test)]\n",
    "\n",
    "spoof_lables = [0]*len(spoof_list_path)\n",
    "human_lables = [1]*len(human_list_path)\n",
    "\n",
    "spoof_df = pd.DataFrame(list(zip(spoof_list_path, spoof_lables)))\n",
    "human_df = pd.DataFrame(list(zip(human_list_path, human_lables)))\n",
    "data_df = pd.concat([spoof_df,human_df], ignore_index=True)\n",
    "\n",
    "data_df = shuffle(data_df)\n",
    "train_data, test_data = train_test_split(data_df, train_size=0.7, stratify=data_df[1], random_state=0)\n",
    "test_data, val_data = train_test_split(test_data, train_size=0.5, stratify=test_data[1], random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ea58b2-aef8-4627-b049-260c1ce53b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "\n",
    "def get_dataset(df):\n",
    "    file_path_ds = tf.data.Dataset.from_tensor_slices(df[0])\n",
    "    label_ds = tf.data.Dataset.from_tensor_slices(df[1])\n",
    "    return tf.data.Dataset.zip((file_path_ds, label_ds))\n",
    "\n",
    "\n",
    "def mel_spec(sounds):\n",
    "    y = tfio.audio.AudioIOTensor(sounds).to_tensor()\n",
    "    y = tf.squeeze(y, -1)\n",
    "    y = tf.cast(y, tf.float32)\n",
    "    y = y/32768.0\n",
    "    spectrogram = tfio.audio.spectrogram(y, nfft=512, window=512, stride=256)\n",
    "    mel_spectrogram = tfio.audio.melscale(spectrogram, rate=16000, mels=128, fmin=0, fmax=8000)\n",
    "    dbscale_mel_spectrogram = tfio.audio.dbscale(mel_spectrogram, top_db=80)\n",
    "    return tf.expand_dims(dbscale_mel_spectrogram, -1)/255\n",
    "\n",
    "\n",
    "def prepare_for_training(ds, shuffle_buffer_size=1024, batch_size=256):\n",
    "    # Randomly shuffle (file_path, label) dataset\n",
    "    ds = ds.shuffle(buffer_size=shuffle_buffer_size)\n",
    "    # Load and decode audio from file paths\n",
    "    ds = ds.map(lambda x,y: (tf.py_function(func=load_and_mel_spec, inp=[x], Tout=tf.float32), y,), num_parallel_calls=AUTOTUNE)\n",
    "    ds = ds.batch(batch_size)\n",
    "    # Prefetch\n",
    "    ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2271fc8e-3e82-4e5c-a7ab-65fdb664e020",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = get_dataset(train_data)\n",
    "train_ds = prepare_for_training(ds)\n",
    "\n",
    "ds = get_dataset(val_data)\n",
    "val_ds = prepare_for_training(ds)\n",
    "\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2ce42c-ef39-4f23-98cb-1c3b4ae83e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in train_ds:\n",
    "    print(i[0].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab9e9a7-fe8c-436e-b6fb-7d5607a194b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_shape=(125, 128, 1)\n",
    "input = keras.Input(shape=input_shape)\n",
    "f = Conv2D(64, kernel_size=(3,3), activation='elu')(input)\n",
    "f = Conv2D(32, kernel_size=(3,3), activation='elu')(f)\n",
    "f = Conv2D(16, kernel_size=(5,5), activation='elu')(f)\n",
    "f = Flatten()(f)\n",
    "d = Dense(320, activation='elu')(f)\n",
    "d = Dense(160, activation='elu')(d)\n",
    "d = Dense(1, activation='sigmoid')(d)\n",
    "\n",
    "model = keras.Model(inputs=input, outputs=d)\n",
    "model.compile(optimizer=tf.optimizers.Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=[\"accuracy\", \"AUC\", TruePositives(), TrueNegatives(), FalsePositives(), FalseNegatives()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da344136-24f6-46e7-9bf8-261810ad29bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "history = model.fit(train_ds, batch_size=256, epochs=10, validation_data=val_ds, shuffle=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
